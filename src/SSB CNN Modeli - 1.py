#!/usr/bin/env python
# coding: utf-8

# CNN modelleri genelde gÃ¶rÃ¼ntÃ¼ verisi veya zaman serisi gibi 2D/3D yapÄ±larla Ã§alÄ±ÅŸÄ±r.
# Senin ÅŸu anki IoT verin ise bir tablo: satÄ±rlar = Ã¶rnekler, sÃ¼tunlar = Ã¶zellikler (yani 1D structured data).
# Bu tabloyu CNN'e uygun hale getirmek iÃ§in "1D Convolutional" model eÄŸiteceÄŸiz.

# In[1]:


import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout


# In[2]:


# Veriyi oku
df = pd.read_csv("C:\\Users\\Lenovo\\Desktop\\OneDrive_2025-05-07\\TON_IoT datasets\\Processed_datasets\\Processed_IoT_dataset\\IoT_Fridge.csv")

# Gereksiz sÃ¼tunlarÄ± Ã§Ä±kar
df.drop(['date', 'time', 'type'], axis=1, inplace=True)

# Kategorik veriyi dÃ¶nÃ¼ÅŸtÃ¼r
df = pd.get_dummies(df, columns=['temp_condition'], drop_first=True)

# GiriÅŸ ve hedef
X = df.drop('label', axis=1)
y = df['label']

# Normalizasyon
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# CNN iÃ§in input ÅŸekli (Ã¶rnek sayÄ±sÄ±, zaman adÄ±mÄ±/girdi boyutu, kanal sayÄ±sÄ±)
X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)

# EÄŸitim-test bÃ¶l
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)


# In[5]:


# Model oluÅŸtur
model = Sequential([
    Conv1D(32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.1),
    Dense(1, activation='sigmoid')  # Binary output
])

# Derle
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# EÄŸit
history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split=0.2, class_weight={0: 1, 1: 4})


# In[6]:


# Tahmin yap
y_pred = model.predict(X_test)
y_pred = [1 if i > 0.5 else 0 for i in y_pred]

# Raporla
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))


# Modeli eÄŸitirken baÅŸta Epoch sayÄ±sÄ±nÄ± 10, dropoutu 0.1 den 0.3 e Ã§ektim ve class_weight={0:1, 1:4} ekledim.
# BÃ¶ylece -class_weight={0:1, 1:4} â€” anomali verisini deÄŸerli hale getirdin
#         -epochs=30 â€” model daha uzun Ã¶ÄŸrenme ÅŸansÄ± buldu
#         -Dropout oranÄ± optimize edildi â€” bilgi kaybÄ± azaltÄ±ldÄ±
#         -CNN katmanlarÄ± doÄŸru yapÄ±landÄ±rÄ±ldÄ± â€” Ã¶rÃ¼ntÃ¼leri daha iyi Ã¶ÄŸrendi

# Anomali tespiti 
# Recall (1 iÃ§in): 1.00 â†’ HiÃ§bir saldÄ±rÄ±yÄ± kaÃ§Ä±rmamÄ±ÅŸsÄ±n 
# Precision (1 iÃ§in): 0.43 â†’ YanlÄ±ÅŸ alarmlar hÃ¢lÃ¢ var ama bu Ã§ok normal.
# 

# F1-Score:
# Normal: 0.87
# Anomali: 0.60
# Makro Ortalama: 0.73
# Bu, modelin her iki sÄ±nÄ±fÄ± da oldukÃ§a dengeli tanÄ±dÄ±ÄŸÄ±nÄ± gÃ¶steriyor.

# In[7]:


from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# ğŸ¯ Modelin decision output'u (olasÄ±lÄ±klar) ile tahminler (0-1 arasÄ±)
y_proba = model.predict(X_test)

# ğŸ“Š ROC eÄŸrisi iÃ§in fpr (False Positive Rate) ve tpr (True Positive Rate) hesapla
fpr, tpr, thresholds = roc_curve(y_test, y_proba)

# ğŸ¯ AUC (Area Under Curve) skoru
roc_auc = auc(fpr, tpr)

# ğŸ¨ ROC eÄŸrisini Ã§iz
plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')  # referans eÄŸrisi
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC EÄŸrisi (CNN Modeli)')
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()


# y_proba: model.predict() sonucu 0-1 arasÄ± olasÄ±lÄ±klardÄ±r. ROC iÃ§in bunlar gerekir.
# fpr ve tpr: her eÅŸik deÄŸeri iÃ§in ne kadar doÄŸru/yanlÄ±ÅŸ tahmin yapÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir.
# AUC: eÄŸrinin altÄ±ndaki alan, 1.00'a ne kadar yakÄ±nsa o kadar iyi.

# ROC EÄŸrisi
# X ekseni: False Positive Rate (YanlÄ±ÅŸ alarm oranÄ±)
# Y ekseni: True Positive Rate (DoÄŸru pozitif oranÄ± â†’ yani anomaliyi yakalama gÃ¼cÃ¼)
# 
# AUC  0.88
# Bu skor [0.50 - 1.00] aralÄ±ÄŸÄ±ndadÄ±r.
# 0.50 = rastgele tahmin.
# 1.00 = mÃ¼kemmel tahmin.
# Benim sonucum 0.88 

# CNN model:
# Anomalileri yÃ¼ksek doÄŸrulukla ayÄ±rt edebiliyor.
# Sistemi gÃ¼venli hale getirmek iÃ§in oldukÃ§a uygun

# In[8]:


from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# ğŸ“Š Confusion matrix hesapla
cm = confusion_matrix(y_test, y_pred)

# ğŸ¨ GÃ¶rselleÅŸtir
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
            xticklabels=["Normal", "Anomali"], 
            yticklabels=["Normal", "Anomali"])

plt.title("Confusion Matrix (CNN Modeli)")
plt.xlabel("Tahmin")
plt.ylabel("GerÃ§ek")
plt.tight_layout()
plt.show()


# annot=True: her hÃ¼creye sayÄ±larÄ± yazdÄ±rÄ±r.
# fmt="d": sayÄ±larÄ± tam sayÄ± olarak formatlar.
# cmap="Blues": mavi tonuyla boyar. 
# xticklabels ve yticklabels: eksen adlarÄ±nÄ± senin verine gÃ¶re ayarladÄ±k.

# DoÄŸru Pozitif (TP): 17.389
# Model gerÃ§ekten anomali olan tÃ¼m verileri doÄŸru tespit etmiÅŸ.
# Recall (1 sÄ±nÄ±fÄ± iÃ§in) = 1.00 â†’ HiÃ§bir saldÄ±rÄ±yÄ± kaÃ§Ä±rmamÄ±ÅŸ.

# False Positive (FP): 23.408
# 23.408 tane normal davranÄ±ÅŸÄ± "anomali" zannetmiÅŸ.
# Precision (1 iÃ§in): 0.43 
# Bu oranÄ± iyileÅŸtirmek mÃ¼mkÃ¼n ama anomali kaÃ§Ä±rmama pahasÄ±na bazÄ± yanlÄ±ÅŸ alarmlar kabul edilebilir.
# Yani: gÃ¼venlik Ã¶ncelikli modellerde bu feda edilebilir 

# DoÄŸru Negatif (TN): 76.619
# Normal olan davranÄ±ÅŸlarÄ± doÄŸru tanÄ±mÄ±ÅŸ.
# Bu da True Negative Rateâ€™in iyi olduÄŸunu gÃ¶steriyor.

# Genel SonuÃ§:
# Anomaliyi asla kaÃ§Ä±rmÄ±yor (1.00 recall) 
# Biraz fazla alarm veriyor ama bu gÃ¼venlik iÃ§in kabul edilebilir 
# Modelin savunmaya geÃ§me refleksi Ã§ok gÃ¼Ã§lÃ¼ 
# Confusion Matrix'teki gÃ¶rselleÅŸtirme farklarÄ± (mavi tonlar) sÄ±nÄ±flar arasÄ± ayrÄ±mÄ± Ã§ok net gÃ¶steriyor 

# Model YapÄ±sÄ±:Conv1D â†’ MaxPooling1D â†’ Dropout â†’ Flatten â†’ Dense â†’ Output

# EÄŸitim SonuÃ§larÄ±:
# Validation Accuracy hep 0.80 civarÄ±nda stabil kalmÄ±ÅŸ. Model overfitting yapmamÄ±ÅŸ.
# Loss deÄŸerleri 30 epoch boyunca dÃ¼ÅŸmÃ¼ÅŸ veya sabit kalmÄ±ÅŸ â†’ Model Ã¶ÄŸreniyor.
# 

# Classification Report:
# Recall (1) = 1.00 â†’ HiÃ§ saldÄ±rÄ± kaÃ§Ä±rmamÄ±ÅŸsÄ±n.
# Precision (1) = 0.43 â†’ YanlÄ±ÅŸ alarmlarÄ± daha sonra filtreleyebilirsin.
# F1-score (anomali) = 0.60 â†’ Dengeli baÅŸarÄ±.

# In[ ]:




